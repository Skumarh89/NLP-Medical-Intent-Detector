{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84LM1QjCR-t8"
   },
   "source": [
    "## 1. GPU Setup in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8jRS5iG1J88a",
    "outputId": "debf1a6f-114f-4761-bf23-a3def3a50dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "d87pSEBuQ35E",
    "outputId": "bed4a20c-d66c-4b60-b926-f0e69015163c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti2TzCHpU9Xq"
   },
   "source": [
    "## 2. Load and analyze data\n",
    "\n",
    "The dataset used is from kaggle: https://www.kaggle.com/paultimothymooney/medical-speech-transcription-and-intent\n",
    "\n",
    "This data contains thousands of audio utterances and corresponding transcriptions for common medical symptoms like “knee pain” or “headache”. Only the transcriptions are used in this project.\n",
    "\n",
    "We can see from below:\n",
    "* column \"phrase\" contains transcriptions describing a person's certain medical symptoms\n",
    "* column \"promp\" contains their corresponding intents (25 intents in total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "zTw2Dkk3VA8j",
    "outputId": "ae13df70-a73b-4290-b583-319838bd5305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 5.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 29.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 45.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 53.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=23a34b0995ad105282132bf7f0353fe246fabf74009fd656a6a611c27ed868bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "N2MP5oB0EJ7F",
    "outputId": "0d420732-63e3-47fa-d969-0317272116b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "FueJ0meBGu1T",
    "outputId": "4f639a9f-3cec-4187-8bee-b5bf96f5668a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>I feel back pain when I carry heavy things</td>\n",
       "      <td>Back pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>I feel great pain in the head</td>\n",
       "      <td>Head ache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>There is a tingling sensation in my neck.</td>\n",
       "      <td>Neck pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>I get breakouts on my chest with red patches t...</td>\n",
       "      <td>Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>I feel discomfort throughout the body in general</td>\n",
       "      <td>Body feels weak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase           prompt\n",
       "2951         I feel back pain when I carry heavy things        Back pain\n",
       "2758                      I feel great pain in the head        Head ache\n",
       "1794          There is a tingling sensation in my neck.        Neck pain\n",
       "376   I get breakouts on my chest with red patches t...             Acne\n",
       "6093   I feel discomfort throughout the body in general  Body feels weak"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('gdrive/My Drive/overview-of-recordings.csv')\n",
    "data1 = data[['phrase','prompt']]\n",
    "data1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "OMQu15Zzt4HI",
    "outputId": "c129c97c-75ab-4e49-c53c-afeae69e5a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phrase    0\n",
       "prompt    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data1.copy()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "E05SMzDrIytN",
    "outputId": "be5e6850-c9e9-4462-9cae-8e5ceb83cab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acne                  328\n",
       "Shoulder pain         320\n",
       "Joint pain            318\n",
       "Infected wound        306\n",
       "Knee pain             305\n",
       "Cough                 293\n",
       "Feeling dizzy         283\n",
       "Muscle pain           282\n",
       "Heart hurts           273\n",
       "Ear ache              270\n",
       "Hair falling out      264\n",
       "Head ache             263\n",
       "Feeling cold          263\n",
       "Skin issue            262\n",
       "Stomach ache          261\n",
       "Back pain             259\n",
       "Neck pain             251\n",
       "Internal pain         248\n",
       "Blurry vision         246\n",
       "Body feels weak       241\n",
       "Hard to breath        233\n",
       "Emotional pain        231\n",
       "Injury from sports    230\n",
       "Foot ache             223\n",
       "Open wound            208\n",
       "Name: prompt, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7Mgt9PVaFrFl",
    "outputId": "641ca72b-6075-494b-82d4-b3ee98b1a035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of intents: 25\n"
     ]
    }
   ],
   "source": [
    "print('Total number of intents: %d'%(len(df['prompt'].value_counts().index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_PN999p9EnS"
   },
   "source": [
    "## 3. Split data to train, validation and test sets\n",
    "\n",
    "I split data to train(70%), validation(10%) and testset (20%) stratified by the variable \"intent\". After stratification, data for each intent will balanced and data for each set will be proportional to 70%, 10% and 20%. That is crucial for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fCzm8IF8JN1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, sentence_test, y, intent_test = train_test_split(df.phrase, df.prompt, stratify = df.prompt,test_size=0.2, random_state=4612)\n",
    "sentence_train, sentence_val, intent_train, intent_val = train_test_split(X, y, stratify = y,test_size=0.125, random_state=4612)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "EOI6Dy20-hNt",
    "outputId": "98218f9a-4400-4162-8049-8dd0b04662c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#examples in training set:4662\n",
      "#examples in validation set:666\n",
      "#examples in test set:1333\n"
     ]
    }
   ],
   "source": [
    "print(f\"#examples in training set:{ sentence_train.shape[0]}\\n#examples in validation set:{ sentence_val.shape[0]}\\n#examples in test set:{ sentence_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI7xNZKGUDeC"
   },
   "source": [
    "## 4. Tokenization and input formatting\n",
    "\n",
    "I Prepare the input data to the correct format before training as follows:\n",
    "* tokenizing all sentences \n",
    "* padding and truncating all sentences to the same length. \n",
    "* Creating the attention masks which explicitly differentiate real tokens from [PAD] tokens. 0 or 1.\n",
    "* encoding the label \"intent\" to numbers. 25 intents to 25 numbers.\n",
    "* creating DataLoaders for our training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "be56de9babe442a4811d85b3339548aa",
      "a8e53b37b054446eb76fe87abbddf460",
      "cee66c2d4b384d7a8b7e946718706f71",
      "b81b76652a25465c8bcfbadba860cf79",
      "671bcb82972a4412a16db716011f17a8",
      "aa96b8556db34c94b9e40474c2381e2f",
      "c38251a78d434a73a6dab64dafcad531",
      "8fb32ff00d84494182a9c075983edf2c"
     ]
    },
    "id": "sBedRwgVNk0f",
    "outputId": "4ef216da-dd83-424d-c0cb-cf0f809c7903"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be56de9babe442a4811d85b3339548aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE =32\n",
    "VALID_BATCH_SIZE = 64\n",
    "EPSILON = 1e-08\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "SEED = 1215\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "lGyiR6ewfUmR",
    "outputId": "af12cf85-0437-4c02-a6c9-74c3c74745cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:39 \n",
      "Mean sentence length:14\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "input = []\n",
    "length=[]\n",
    "for sent in sentence_train:\n",
    "\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    input.append(input_ids)\n",
    "    length.append(len(input_ids))\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "    mean_len = sum(length)/len(length)\n",
    "print('Max sentence length:%d \\nMean sentence length:%d' % (max_len,mean_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmP18btQcDtk"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "  batch = tokenizer(list(sentence),             \n",
    "                  is_pretokenized=False,\n",
    "                  padding=True, \n",
    "                  truncation=True,\n",
    "                  return_tensors=\"pt\")\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzj1fPMi4trY"
   },
   "outputs": [],
   "source": [
    "tok_train = tokenize(sentence_train)\n",
    "tok_val = tokenize(sentence_val)\n",
    "tok_test = tokenize(sentence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpUEorEFS9DW"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "label_train = torch.tensor((LE.fit_transform(intent_train)))\n",
    "label_val = torch.tensor((LE.fit_transform(intent_val)))\n",
    "label_test = torch.tensor((LE.fit_transform(intent_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7pdk4xI4q79"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(tok_train['input_ids'], tok_train['attention_mask'],label_train)\n",
    "validation_dataset = TensorDataset(tok_val['input_ids'], tok_val['attention_mask'],label_val)\n",
    "test_dataset = TensorDataset(tok_test['input_ids'], tok_test['attention_mask'],label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEas6b_5gdt3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = TRAIN_BATCH_SIZE \n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset, # validation samples.\n",
    "            sampler = SequentialSampler(validation_dataset), \n",
    "            batch_size = VALID_BATCH_SIZE # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "            validation_dataset, \n",
    "            sampler = SequentialSampler(validation_dataset), \n",
    "            batch_size = VALID_BATCH_SIZE \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rgEw1M6SdEh"
   },
   "source": [
    "## 5. Train BERT classification model\n",
    "\n",
    "I use BertForSequenceClassification, a BERT model with an added single linear layer on top for classification. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "8b9d2f88b57246cf96e9a6c2c89ab718",
      "f9be3136155b4142a063643b614b0dd1",
      "d30bd8a5f8ec48859cd6a0060adf8413",
      "048c8b900b2c476cb650e19e2ef91f48",
      "17e5c0b7d44f45c8b790243b90559409",
      "1bf16755fa3e4a2a82b89b3b3de44b85",
      "6dc92dc6a3a746c2b71fa7376451325e",
      "be3a7b235c7a4a4399a10dd783abc5ca",
      "6d5059f5a143464594775b110e1c7ee0",
      "2a9bda2c09524a87bbd15684e89d799d",
      "2e6558cce2fe490eac8a1d3515a50f6c",
      "5f9a469c8723465aafc26e8a19513cd8",
      "d913a3797b7c4265936a9c7804947049",
      "4bee615ac43d42e984797361b9b3fa9f",
      "de947603ca6c4156b0c4a81f5a9d4bb1",
      "0d334b6fdec9409b902289c6045f50d1"
     ]
    },
    "id": "ES9tG3TtZeKd",
    "outputId": "418292ac-dc38-4d93-f864-7fd6733a25ea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9d2f88b57246cf96e9a6c2c89ab718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5059f5a143464594775b110e1c7ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 25)\n",
    "model.cuda() \n",
    "\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                  lr = LEARNING_RATE, \n",
    "                  eps = EPSILON\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HN98ADE7daEY"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7vskXYEwOrM"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))   \n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Qr6xDxPmZH8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/Tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSf6uUcKe0ak"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "def train(epochs):\n",
    "  total_t0 = time.time() \n",
    "  tr_loss = 0\n",
    "  n_correct = 0\n",
    "  nb_tr_steps = 0\n",
    "  nb_tr_examples = 0\n",
    "  \n",
    "  for epoch in range(0, epochs):\n",
    "      print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "      print('Training...')\n",
    "\n",
    "      t0 = time.time()     \n",
    "      total_tr_loss = 0\n",
    "      total_n_correct = 0\n",
    "      total_nb_tr_examples = 0\n",
    "      model.train()    \n",
    "\n",
    "      for step, batch in enumerate(train_dataloader, 0):     \n",
    "          input_ids = batch[0].to(device, dtype = torch.long)\n",
    "          input_mask = batch[1].to(device, dtype = torch.long)\n",
    "          labels = batch[2].to(device, dtype = torch.long)\n",
    "\n",
    "          model.zero_grad()       \n",
    "\n",
    "          outputs = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n",
    "          loss_function = torch.nn.CrossEntropyLoss()\n",
    "          loss = loss_function(outputs[0], labels) \n",
    "          tr_loss += loss.item() \n",
    "          total_tr_loss += loss.item()\n",
    "          big_val, big_idx = torch.max(outputs[0], dim=1)\n",
    "          n_correct += calcuate_accu(big_idx, labels)  \n",
    "          total_n_correct += calcuate_accu(big_idx, labels)                  \n",
    "          nb_tr_steps += 1\n",
    "          nb_tr_examples+=labels.size(0)\n",
    "          total_nb_tr_examples+=labels.size(0)\n",
    "\n",
    "          if step % 20==19:\n",
    "              loss_step = tr_loss/nb_tr_steps\n",
    "              accu_step = n_correct/nb_tr_examples  \n",
    "              print(f\"Training Loss per 20 steps(batches): {loss_step}\")\n",
    "              print(f\"Training Accuracy per 20 steps(batches): {accu_step}\")\n",
    "              elapsed = format_time(time.time() - t0)      \n",
    "              print('Batch {} of {}.  Elapsed: {:}.'.format(step+1, len(train_dataloader), elapsed))\n",
    "              tr_loss = 0;n_correct = 0;nb_tr_steps = 0;nb_tr_examples = 0\n",
    "                \n",
    "          loss.backward() \n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # prevent the \"exploding gradients\" problem.\n",
    "          optimizer.step()\n",
    "          scheduler.step() \n",
    "\n",
    "      train_loss_per_epoch = total_tr_loss / len(train_dataloader)            \n",
    "      train_accuracy_per_epoch=total_n_correct/total_nb_tr_examples\n",
    "      training_time = format_time(time.time() - t0)\n",
    "\n",
    "      print(\"\")\n",
    "      print(\"training loss per epoch: {0:.2f}\".format(train_loss_per_epoch))\n",
    "      print(\"training accuracy per epoch: {0:.2f}\".format(train_accuracy_per_epoch))\n",
    "      print(\"Training 1 epcoh took: {:}\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zv7RYg3fPXkJ",
    "outputId": "aa06ad10-991b-4005-cb85-5973298d35b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "Training Loss per 20 steps(batches): 3.207607901096344\n",
      "Training Accuracy per 20 steps(batches): 0.0671875\n",
      "Batch 20 of 146.  Elapsed: 0:00:05.\n",
      "Training Loss per 20 steps(batches): 3.1109325170516966\n",
      "Training Accuracy per 20 steps(batches): 0.0859375\n",
      "Batch 40 of 146.  Elapsed: 0:00:09.\n",
      "Training Loss per 20 steps(batches): 2.941100037097931\n",
      "Training Accuracy per 20 steps(batches): 0.1578125\n",
      "Batch 60 of 146.  Elapsed: 0:00:14.\n",
      "Training Loss per 20 steps(batches): 2.7166395783424377\n",
      "Training Accuracy per 20 steps(batches): 0.2734375\n",
      "Batch 80 of 146.  Elapsed: 0:00:18.\n",
      "Training Loss per 20 steps(batches): 2.4430582165718078\n",
      "Training Accuracy per 20 steps(batches): 0.4875\n",
      "Batch 100 of 146.  Elapsed: 0:00:23.\n",
      "Training Loss per 20 steps(batches): 2.191276413202286\n",
      "Training Accuracy per 20 steps(batches): 0.6421875\n",
      "Batch 120 of 146.  Elapsed: 0:00:27.\n",
      "Training Loss per 20 steps(batches): 1.9297438085079193\n",
      "Training Accuracy per 20 steps(batches): 0.75625\n",
      "Batch 140 of 146.  Elapsed: 0:00:32.\n",
      "\n",
      "training loss per epoch: 2.61\n",
      "training accuracy per epoch: 0.37\n",
      "Training 1 epcoh took: 0:00:33\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "Training Loss per 20 steps(batches): 1.5861441722282996\n",
      "Training Accuracy per 20 steps(batches): 0.8625304136253041\n",
      "Batch 20 of 146.  Elapsed: 0:00:04.\n",
      "Training Loss per 20 steps(batches): 1.3843166470527648\n",
      "Training Accuracy per 20 steps(batches): 0.865625\n",
      "Batch 40 of 146.  Elapsed: 0:00:09.\n",
      "Training Loss per 20 steps(batches): 1.14256412088871\n",
      "Training Accuracy per 20 steps(batches): 0.925\n",
      "Batch 60 of 146.  Elapsed: 0:00:14.\n",
      "Training Loss per 20 steps(batches): 0.9932358473539352\n",
      "Training Accuracy per 20 steps(batches): 0.9359375\n",
      "Batch 80 of 146.  Elapsed: 0:00:18.\n",
      "Training Loss per 20 steps(batches): 0.8442562162876129\n",
      "Training Accuracy per 20 steps(batches): 0.9625\n",
      "Batch 100 of 146.  Elapsed: 0:00:23.\n",
      "Training Loss per 20 steps(batches): 0.6967461615800857\n",
      "Training Accuracy per 20 steps(batches): 0.9703125\n",
      "Batch 120 of 146.  Elapsed: 0:00:27.\n",
      "Training Loss per 20 steps(batches): 0.6236915081739426\n",
      "Training Accuracy per 20 steps(batches): 0.9765625\n",
      "Batch 140 of 146.  Elapsed: 0:00:32.\n",
      "\n",
      "training loss per epoch: 1.01\n",
      "training accuracy per epoch: 0.93\n",
      "Training 1 epcoh took: 0:00:34\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "Training Loss per 20 steps(batches): 0.5283277688118128\n",
      "Training Accuracy per 20 steps(batches): 0.9829683698296837\n",
      "Batch 20 of 146.  Elapsed: 0:00:05.\n",
      "Training Loss per 20 steps(batches): 0.43248309642076493\n",
      "Training Accuracy per 20 steps(batches): 0.990625\n",
      "Batch 40 of 146.  Elapsed: 0:00:09.\n",
      "Training Loss per 20 steps(batches): 0.4051169976592064\n",
      "Training Accuracy per 20 steps(batches): 0.9828125\n",
      "Batch 60 of 146.  Elapsed: 0:00:14.\n",
      "Training Loss per 20 steps(batches): 0.3535314604640007\n",
      "Training Accuracy per 20 steps(batches): 0.984375\n",
      "Batch 80 of 146.  Elapsed: 0:00:19.\n",
      "Training Loss per 20 steps(batches): 0.31365336030721663\n",
      "Training Accuracy per 20 steps(batches): 0.9921875\n",
      "Batch 100 of 146.  Elapsed: 0:00:23.\n",
      "Training Loss per 20 steps(batches): 0.27215839698910715\n",
      "Training Accuracy per 20 steps(batches): 0.996875\n",
      "Batch 120 of 146.  Elapsed: 0:00:28.\n",
      "Training Loss per 20 steps(batches): 0.2572125673294067\n",
      "Training Accuracy per 20 steps(batches): 0.9921875\n",
      "Batch 140 of 146.  Elapsed: 0:00:33.\n",
      "\n",
      "training loss per epoch: 0.36\n",
      "training accuracy per epoch: 0.99\n",
      "Training 1 epcoh took: 0:00:34\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "Training Loss per 20 steps(batches): 0.23088697630625504\n",
      "Training Accuracy per 20 steps(batches): 0.9987834549878345\n",
      "Batch 20 of 146.  Elapsed: 0:00:05.\n",
      "Training Loss per 20 steps(batches): 0.20307304486632347\n",
      "Training Accuracy per 20 steps(batches): 0.9984375\n",
      "Batch 40 of 146.  Elapsed: 0:00:09.\n",
      "Training Loss per 20 steps(batches): 0.19804720655083657\n",
      "Training Accuracy per 20 steps(batches): 0.9953125\n",
      "Batch 60 of 146.  Elapsed: 0:00:14.\n",
      "Training Loss per 20 steps(batches): 0.19199633449316025\n",
      "Training Accuracy per 20 steps(batches): 0.996875\n",
      "Batch 80 of 146.  Elapsed: 0:00:19.\n",
      "Training Loss per 20 steps(batches): 0.17527931705117225\n",
      "Training Accuracy per 20 steps(batches): 0.996875\n",
      "Batch 100 of 146.  Elapsed: 0:00:24.\n",
      "Training Loss per 20 steps(batches): 0.17845937386155128\n",
      "Training Accuracy per 20 steps(batches): 0.9953125\n",
      "Batch 120 of 146.  Elapsed: 0:00:28.\n",
      "Training Loss per 20 steps(batches): 0.19288426265120506\n",
      "Training Accuracy per 20 steps(batches): 0.990625\n",
      "Batch 140 of 146.  Elapsed: 0:00:33.\n",
      "\n",
      "training loss per epoch: 0.19\n",
      "training accuracy per epoch: 1.00\n",
      "Training 1 epcoh took: 0:00:35\n"
     ]
    }
   ],
   "source": [
    "train(epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0GRYwY0dTs9"
   },
   "source": [
    "## 6. Test the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlTEWtXojLWy"
   },
   "outputs": [],
   "source": [
    "def valid(model, validation_loader):\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  nb_val_examples = 0\n",
    "  n_correct = 0\n",
    "  with torch.no_grad():\n",
    "    for _, data in enumerate(validation_loader, 0): \n",
    "      ids = data[0].to(device, dtype = torch.long)\n",
    "      mask = data[1].to(device, dtype = torch.long)\n",
    "      targets = data[2].to(device, dtype = torch.long)\n",
    "      outputs = model(ids, mask)\n",
    "      loss_function = torch.nn.CrossEntropyLoss()\n",
    "      loss = loss_function(outputs[0], targets)\n",
    "      val_loss += loss.item()\n",
    "      big_val, big_idx = torch.max(outputs[0], dim=1)\n",
    "      n_correct += calcuate_accu(big_idx, targets)\n",
    "      nb_val_examples+=targets.size(0)\n",
    "\n",
    "  val_ave_loss = val_loss/len(validation_loader)\n",
    "  val_accu = (n_correct*100)/nb_val_examples\n",
    "  print(\"Loss on validation/test data: %0.2f\" % val_ave_loss)\n",
    "  print(\"Accuracy on validation/test data: %0.2f%%\" % val_accu)\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "A_zvJtc8jzUf",
    "outputId": "3d04543b-6c07-4760-ecee-3bf589b2cddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation/test data: 0.14\n",
      "Accuracy on validation/test data: 99.40%\n"
     ]
    }
   ],
   "source": [
    "valid(model, validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kbEq1nfdlTS"
   },
   "source": [
    "## 7. Obtain test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "veyLRX0X7F34",
    "outputId": "e4bf7f26-4f2c-4597-e3d9-9fe9f0d9debd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation/test data: 0.14\n",
      "Accuracy on validation/test data: 99.40%\n"
     ]
    }
   ],
   "source": [
    "valid(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXuYH1QzdxCq"
   },
   "source": [
    "## 8. Save the model, tokenizer and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "TgJ1ZiFbOv-G",
    "outputId": "ab7a2118-5aab-4cef-ec37-5c6f1884a987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/vocab.txt',\n",
       " './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/special_tokens_map.json',\n",
       " './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_dir = './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isbt1ZKiGc6U"
   },
   "outputs": [],
   "source": [
    "df_label = pd.DataFrame(tuple(zip(range(25),LE.classes_)), columns=['id','intent'])\n",
    "df_label.to_pickle('./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/df_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDBt5d0vSxjG"
   },
   "outputs": [],
   "source": [
    "!cp -r ./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/ \"gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8LixoWUeaz_"
   },
   "source": [
    "## 9. Prepare the model for deployment\n",
    "* Load the saved model, tokenizer and labels \n",
    "* Create a medical_symptom_detector function with the loaded model, tokenizer and labels, which helps predict the medical intent of a medical message. \n",
    "* test the detector on an unseen example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "XakLziFwLyZ5",
    "outputId": "0dd6757e-c2aa-470a-8155-16601aecb5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "input_dir = 'gdrive/My Drive/saved_bert_model_and_tokenizer/'\n",
    "\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(input_dir)\n",
    "loaded_model.eval()\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(input_dir)\n",
    "loaded_df_label = pd.read_pickle('gdrive/My Drive/saved_bert_model_and_tokenizer/df_label.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrAUw6PmVyoo"
   },
   "outputs": [],
   "source": [
    "\n",
    "def medical_symptom_detector(intent):\n",
    "\n",
    "  pt_batch = loaded_tokenizer(\n",
    "  intent,\n",
    "  padding=True,\n",
    "  truncation=True,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "  pt_outputs = loaded_model(**pt_batch)\n",
    "  __, id = torch.max(pt_outputs[0], dim=1)\n",
    "  prediction = loaded_df_label.iloc[[id.item()]]['intent'].item()\n",
    "  print('You may have a medical condition: %s. Would you like me to transfer your call to your doctor?'%(prediction))\n",
    "  return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B6XsSWSTHz5C",
    "outputId": "a8629dab-c6eb-4774-d153-ff04f3144f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may have a medical condition: Knee pain. Would you like me to transfer your call to your doctor?\n"
     ]
    }
   ],
   "source": [
    "input = 'my left knee hurts so much'\n",
    "medical_symptom_detector(input)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "medical_intent_detector_Using_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "048c8b900b2c476cb650e19e2ef91f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be3a7b235c7a4a4399a10dd783abc5ca",
      "placeholder": "​",
      "style": "IPY_MODEL_6dc92dc6a3a746c2b71fa7376451325e",
      "value": " 433/433 [00:00&lt;00:00, 1.39kB/s]"
     }
    },
    "0d334b6fdec9409b902289c6045f50d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17e5c0b7d44f45c8b790243b90559409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1bf16755fa3e4a2a82b89b3b3de44b85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9bda2c09524a87bbd15684e89d799d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e6558cce2fe490eac8a1d3515a50f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bee615ac43d42e984797361b9b3fa9f",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d913a3797b7c4265936a9c7804947049",
      "value": 440473133
     }
    },
    "4bee615ac43d42e984797361b9b3fa9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f9a469c8723465aafc26e8a19513cd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d334b6fdec9409b902289c6045f50d1",
      "placeholder": "​",
      "style": "IPY_MODEL_de947603ca6c4156b0c4a81f5a9d4bb1",
      "value": " 440M/440M [00:09&lt;00:00, 46.5MB/s]"
     }
    },
    "671bcb82972a4412a16db716011f17a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6d5059f5a143464594775b110e1c7ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e6558cce2fe490eac8a1d3515a50f6c",
       "IPY_MODEL_5f9a469c8723465aafc26e8a19513cd8"
      ],
      "layout": "IPY_MODEL_2a9bda2c09524a87bbd15684e89d799d"
     }
    },
    "6dc92dc6a3a746c2b71fa7376451325e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b9d2f88b57246cf96e9a6c2c89ab718": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d30bd8a5f8ec48859cd6a0060adf8413",
       "IPY_MODEL_048c8b900b2c476cb650e19e2ef91f48"
      ],
      "layout": "IPY_MODEL_f9be3136155b4142a063643b614b0dd1"
     }
    },
    "8fb32ff00d84494182a9c075983edf2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8e53b37b054446eb76fe87abbddf460": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa96b8556db34c94b9e40474c2381e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b81b76652a25465c8bcfbadba860cf79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fb32ff00d84494182a9c075983edf2c",
      "placeholder": "​",
      "style": "IPY_MODEL_c38251a78d434a73a6dab64dafcad531",
      "value": " 232k/232k [00:00&lt;00:00, 806kB/s]"
     }
    },
    "be3a7b235c7a4a4399a10dd783abc5ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be56de9babe442a4811d85b3339548aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cee66c2d4b384d7a8b7e946718706f71",
       "IPY_MODEL_b81b76652a25465c8bcfbadba860cf79"
      ],
      "layout": "IPY_MODEL_a8e53b37b054446eb76fe87abbddf460"
     }
    },
    "c38251a78d434a73a6dab64dafcad531": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cee66c2d4b384d7a8b7e946718706f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa96b8556db34c94b9e40474c2381e2f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_671bcb82972a4412a16db716011f17a8",
      "value": 231508
     }
    },
    "d30bd8a5f8ec48859cd6a0060adf8413": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bf16755fa3e4a2a82b89b3b3de44b85",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17e5c0b7d44f45c8b790243b90559409",
      "value": 433
     }
    },
    "d913a3797b7c4265936a9c7804947049": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de947603ca6c4156b0c4a81f5a9d4bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9be3136155b4142a063643b614b0dd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
